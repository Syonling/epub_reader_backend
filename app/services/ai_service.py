"""
AI æ–‡æœ¬åˆ†ææœåŠ¡ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
æ”¯æŒå¤šç§ LLM APIï¼šOpenAI, Claude, Gemini, Ollama
"""
import json, os
from typing import Dict, Optional
from config import Config
from app.utils.language_detector import detect_language

# ================================
# åŸºç¡€åˆ†æå™¨ç±»
# ================================
class BaseAnalyzer:
    """LLM åˆ†æå™¨åŸºç±»"""
    
    def __init__(self):
        self.config = Config
    
    def analyze(self, text: str) -> Dict:
        """åˆ†ææ–‡æœ¬ï¼ˆéœ€è¦å­ç±»å®ç°ï¼‰"""
        raise NotImplementedError
    
    def _build_prompt(self, text: str) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        return f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œæä¾›è¯¦ç»†çš„è¯­è¨€å­¦ä¹ è¾…åŠ©ä¿¡æ¯ï¼š

                æ–‡æœ¬: {text}

                è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
                1. è¯­è¨€ç±»å‹ï¼ˆä¸­æ–‡/æ—¥æ–‡/è‹±æ–‡ï¼‰
                2. ç¿»è¯‘ï¼ˆå¦‚æœæ˜¯å¤–è¯­ï¼Œç¿»è¯‘æˆä¸­æ–‡ï¼›å¦‚æœæ˜¯ä¸­æ–‡ï¼Œç¿»è¯‘æˆè‹±æ–‡ï¼‰
                3. è¯­æ³•ç»“æ„åˆ†æ
                4. é‡ç‚¹è¯æ±‡åŠè§£é‡Š
                5. æ–‡åŒ–èƒŒæ™¯æˆ–ä½¿ç”¨åœºæ™¯è¯´æ˜

                è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚"""

    def _load_prompt(self) -> str:
        """åŠ è½½æç¤ºè¯æ–‡ä»¶"""
        prompt_path = os.path.join(os.path.dirname(__file__), "..", "..", "prompt.txt")
        try:
            with open(prompt_path, "r", encoding="utf-8") as f:
                return f.read()
        except FileNotFoundError:
            # â­ è¿”å›é»˜è®¤ promptï¼Œä¸èƒ½è¿”å› None
            return """ã‚ãªãŸã¯æ—¥æœ¬èªã®å°‚é–€åˆ†æè€…ã§ã™ã€‚
            JSONå½¢å¼ã§ä»¥ä¸‹ã®æƒ…å ±ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
            {
            "translation": "ä¸­å›½èªè¨³",
            "grammar_points": [],
            "vocabulary": [],
            "special_notes": []
            }"""

# ================================
# OpenAI åˆ†æå™¨
# ================================
class OpenAIAnalyzer(BaseAnalyzer):
    """OpenAI GPT åˆ†æå™¨"""
    
    def __init__(self):
        super().__init__()
        from openai import OpenAI
        
        # æ”¯æŒè‡ªå®šä¹‰ base_urlï¼ˆç”¨äºä»£ç†æˆ–å…¼å®¹æ¥å£ï¼‰
        client_kwargs = {'api_key': self.config.OPENAI_API_KEY}
        if self.config.OPENAI_BASE_URL:
            client_kwargs['base_url'] = self.config.OPENAI_BASE_URL
        
        self.client = OpenAI(**client_kwargs)
    
    def analyze(self, text: str) -> Dict:
        """ä½¿ç”¨ OpenAI API åˆ†ææ–‡æœ¬"""
        try:
            prompt = self._load_prompt()
            response = self.client.chat.completions.create(
                model=self.config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": text}
                ],
                response_format={"type": "json_object"},  # â­ å¼ºåˆ¶ JSON
                temperature=0.3
            )
            
            analysis = response.choices[0].message.content
            
            # å°è¯•è§£æä¸ºJSONï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›åŸå§‹æ–‡æœ¬
            # try:
            #     analysis_data = json.loads(content)
            # except json.JSONDecodeError:
            #     analysis_data = {'raw_response': content}
            
            return {
                # 'provider': 'OpenAI',
                # 'model': self.config.OPENAI_MODEL,
                'analysis': analysis,
                'tokens_used': response.usage.total_tokens,
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'provider': 'OpenAI',
                'error': str(e),
                'status': 'error'
            }


# ================================
# Anthropic Claude åˆ†æå™¨
# ================================
class ClaudeAnalyzer(BaseAnalyzer):
    """Anthropic Claude åˆ†æå™¨"""
    
    def __init__(self):
        super().__init__()
        import anthropic
        self.client = anthropic.Anthropic(api_key=self.config.ANTHROPIC_API_KEY)
    
    def analyze(self, text: str) -> Dict:
        import json
        
        response = self.client.messages.create(
            model=self.config.CLAUDE_MODEL,
            max_tokens=2000,
            messages=[
                {"role": "user", "content": f"{self._load_prompt()}\n\n{text}"}
            ]
        )
        
        # Claude è¿”å›çš„ content å¯èƒ½éœ€è¦æå–
        analysis = response.content[0].text
        
        # âš ï¸ ç¡®ä¿æ˜¯ JSON å­—ç¬¦ä¸²
        # å¦‚æœ Claude è¿”å›äº†é JSONï¼Œéœ€è¦å¤„ç†
        try:
            # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆ JSON
            json.loads(analysis)
        except:
            # å¦‚æœä¸æ˜¯ JSONï¼ŒåŒ…è£…ä¸€ä¸‹
            analysis = json.dumps({
                "translation": "è§£æå¤±è´¥",
                "grammar_points": [],
                "vocabulary": [],
                "special_notes": [f"åŸå§‹è¾“å‡º: {analysis}"]
            }, ensure_ascii=False)
        
        return {
            'provider': 'claude',
            'model': self.config.CLAUDE_MODEL,
            'analysis': analysis,  # âœ… JSON å­—ç¬¦ä¸²
            'tokens_used': response.usage.input_tokens + response.usage.output_tokens,
            'status': 'success'
        }


# ================================
# Google Gemini åˆ†æå™¨
# ================================
class GeminiAnalyzer(BaseAnalyzer):
    """Google Gemini åˆ†æå™¨"""
    
    def __init__(self):
        super().__init__()
        import google.generativeai as genai
        genai.configure(api_key=self.config.GEMINI_API_KEY)
        self.model = genai.GenerativeModel(self.config.GEMINI_MODEL)
    
    def analyze(self, text: str) -> Dict:
        import json
        
        generation_config = {
            "temperature": 0.3,
            "max_output_tokens": 2000,
            "response_mime_type": "application/json"  # â­ Gemini çš„ JSON æ¨¡å¼
        }
        
        response = self.model.generate_content(
            f"{self._load_prompt()}\n\n{text}",
            generation_config=generation_config
        )
        
        analysis = response.text
        
        return {
            'provider': 'gemini',
            'model': self.config.GEMINI_MODEL,
            'analysis': analysis,  # âœ… JSON å­—ç¬¦ä¸²
            'tokens_used': 0,  # Gemini å¯èƒ½éœ€è¦ä»å…¶ä»–åœ°æ–¹è·å–
            'status': 'success'
        }


# ================================
# Ollama æœ¬åœ°æ¨¡å‹åˆ†æå™¨
# ================================
class OllamaAnalyzer(BaseAnalyzer):
    """Ollama æœ¬åœ°æ¨¡å‹åˆ†æå™¨"""
    
    def __init__(self):
        super().__init__()
        import requests
        self.base_url = self.config.OLLAMA_BASE_URL
        self.requests = requests
    
    def analyze(self, text: str) -> Dict:
        import json
        import requests
        
        response = requests.post(
            f'{self.config.OLLAMA_BASE_URL}/api/generate',
            json={
                'model': self.config.OLLAMA_MODEL,
                'prompt': f"{self._load_prompt()}\n\n{text}",
                'format': 'json',  # â­ Ollama çš„ JSON æ¨¡å¼
                'stream': False
            }
        )
        
        data = response.json()
        analysis = data.get('response', '{}')
        
        return {
            'provider': 'ollama',
            'model': self.config.OLLAMA_MODEL,
            'analysis': analysis,  # âœ… JSON å­—ç¬¦ä¸²
            'tokens_used': 0,
            'status': 'success'
        }


# ================================
# Echo æµ‹è¯•åˆ†æå™¨ï¼ˆä¸è°ƒç”¨å®é™…APIï¼‰
# ================================
class EchoAnalyzer(BaseAnalyzer):
    """Echo åˆ†æå™¨ - ç”¨äºæµ‹è¯•ï¼Œè¿”å›æ¨¡æ‹Ÿçš„æ—¥è¯­åˆ†æç»“æœ"""
    
    def analyze(self, text: str) -> Dict:
        """è¿”å›æ¨¡æ‹Ÿçš„åˆ†æç»“æœï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰"""
        
        analysis_json = self._generate_japanese_mock(text)
        
        # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²ï¼ˆä¸ DeepSeek æ ¼å¼ä¸€è‡´ï¼‰
        import json
        return {
            'provider': 'echo',
            'model': 'echo (æµ‹è¯•æ¨¡å¼)',
            'analysis': json.dumps(analysis_json, ensure_ascii=False),
            'tokens_used': 0,
            'status': 'success'
        }
    
    def _generate_japanese_mock(self, text: str) -> Dict:
        """ç”Ÿæˆæ—¥è¯­æ¨¡æ‹Ÿæ•°æ®ï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰"""
        return {
            "translation": f"ã€æ¨¡æ‹Ÿç¿»è¯‘ã€‘{text}ï¼ˆè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç¿»è¯‘ï¼‰",
            "grammar_points": [
                {
                    "pattern": "ã€œã¦ã„ã‚‹",
                    "explanation": "è¡¨ç¤ºåŠ¨ä½œçš„æŒç»­æˆ–ç»“æœçŠ¶æ€ï¼ˆæ¨¡æ‹Ÿè¯­æ³•ç‚¹ï¼‰",
                    "example_in_sentence": text[:10] if len(text) > 10 else text,
                    "level": "N2",
                    "is_special": False
                },
                {
                    "pattern": "ã€œã‚‰ã‚Œã‚‹",
                    "explanation": "è¡¨ç¤ºè¢«åŠ¨æˆ–å¯èƒ½ï¼ˆæ¨¡æ‹Ÿè¯­æ³•ç‚¹ï¼‰",
                    "example_in_sentence": text[:10] if len(text) > 10 else text,
                    "level": "N2",
                    "is_special": False
                }
            ],
            "vocabulary": [
                {
                    "word": text[:5] if len(text) >= 5 else text,
                    "reading": "ã‚‚ã",
                    "meaning": "æ¨¡æ‹Ÿè¯æ±‡",
                    "level": "N2",
                    "conjugation": {
                        "has_conjugation": True,
                        "original_form": "æ¨¡æ‹ŸåŸå‹",
                        "current_form": text[:5] if len(text) >= 5 else text,
                        "conjugation_type": "å—èº«å½¢ï¼‹ã¦ã„ã‚‹",
                        "reason": "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„æ´»ç”¨è¯´æ˜ï¼Œç”¨äºæµ‹è¯• Echo æ¨¡å¼"
                    }
                },
                {
                    "word": "ãƒ†ã‚¹ãƒˆ",
                    "reading": "ã¦ã™ã¨",
                    "meaning": "æµ‹è¯•",
                    "level": "N2",
                    "conjugation": {
                        "has_conjugation": False
                    }
                }
            ],
            "special_notes": [
                "âš ï¸ è¿™æ˜¯ Echo æµ‹è¯•æ¨¡å¼çš„æ¨¡æ‹Ÿè¾“å‡º",
                "ğŸ’¡ é…ç½®çœŸå®çš„ API å¯†é’¥åï¼Œå°†è¿”å›å®é™…çš„ AI åˆ†æç»“æœ"
            ]
        }


# ================================
# Deepseek åˆ†æå™¨ï¼‰
# ================================
class DeepSeekAnalyzer(BaseAnalyzer):
    """DeepSeek AI åˆ†æå™¨"""
    
    def __init__(self):
        super().__init__()
        # DeepSeek ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
        from openai import OpenAI
        
        self.client = OpenAI(
            api_key=self.config.DEEPSEEK_API_KEY,
            base_url="https://api.deepseek.com"
        )
    
    def analyze(self, text: str) -> Dict:
        """ä½¿ç”¨ DeepSeek åˆ†ææ–‡æœ¬"""
        try:
            # è¯»å–æç¤ºè¯
            prompt = self._load_prompt()
            
            response = self.client.chat.completions.create(
                model=self.config.DEEPSEEK_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": text}
                ],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=2000
            )
            
            analysis = response.choices[0].message.content
            
            return {
                # 'provider': 'deepseek',
                # 'model': self.config.DEEPSEEK_MODEL,
                'analysis': analysis,
                'tokens_used': response.usage.total_tokens if hasattr(response, 'usage') else 0,
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'provider': 'deepseek',
                'error': str(e),
                'status': 'error'
            }
    


# ================================
# åˆ†æå™¨å·¥å‚
# ================================
class AnalyzerFactory:
    """åˆ†æå™¨å·¥å‚ç±»"""
    
    _analyzers = {
        'openai': OpenAIAnalyzer,
        'claude': ClaudeAnalyzer,
        'gemini': GeminiAnalyzer,
        'ollama': OllamaAnalyzer,
        'echo': EchoAnalyzer,
        'deepseek': DeepSeekAnalyzer,
    }
    
    @classmethod
    def create_analyzer(cls, provider: Optional[str] = None) -> BaseAnalyzer:
        """åˆ›å»ºåˆ†æå™¨å®ä¾‹"""
        provider = provider or Config.AI_PROVIDER
        
        analyzer_class = cls._analyzers.get(provider)
        if not analyzer_class:
            raise ValueError(f"ä¸æ”¯æŒçš„ AI æä¾›å•†: {provider}")
        
        return analyzer_class()
    
    @classmethod
    def get_available_providers(cls) -> list:
        """è·å–å¯ç”¨çš„æä¾›å•†åˆ—è¡¨"""
        return list(cls._analyzers.keys())


# ================================
# ä¸»è¦çš„åˆ†æå‡½æ•°ï¼ˆåŒæ­¥ï¼‰
# ================================
def analyze_text_with_ai(text: str, provider: Optional[str] = None) -> Dict:
    """
    ä½¿ç”¨AIåˆ†ææ–‡æœ¬ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
    
    Args:
        text: è¦åˆ†æçš„æ–‡æœ¬
        provider: AIæä¾›å•† (å¯é€‰)
    
    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    try:
        analyzer = AnalyzerFactory.create_analyzer(provider)
        result = analyzer.analyze(text)
        return result
        
    except Exception as e:
        return {
            'provider': provider or Config.AI_PROVIDER,
            'error': str(e),
            'status': 'error'
        }