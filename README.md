# ğŸ“š EPUB Reader Backend

æ—¥æœ¬èªå­¦ç¿’è€…ï¼ˆç‰¹ã«ä¸­å›½èªãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ï¼‰å‘ã‘ã«ç‰¹åˆ¥ã«è¨­è¨ˆã•ã‚ŒãŸã€å¼·åŠ›ãªEPUBãƒªãƒ¼ãƒ€ãƒ¼ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚è¤‡æ•°ã®AIãƒ¢ãƒ‡ãƒ«ã€åŒ…æ‹¬çš„ãªæ—¥æœ¬èªè¾æ›¸æ¤œç´¢ã€å‹•è©ã®æ´»ç”¨è§£æã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

> ğŸ“± Frontendï¼š[EPUB Reader ï¼ˆFlutter Appï¼‰](https://github.com/Syonling/epub_reader_Androidfrontend#)

![License: CC BY-NC 4.0](https://img.shields.io/badge/License-CC%20BY--NC%204.0-blue)
![Python](https://img.shields.io/badge/Python-3.11.0+-brightgreen)
![Flutter](https://img.shields.io/badge/Flutter-3.35.6-blue)
![Flask](https://img.shields.io/badge/Flask-3.1.2-orange)

## ğŸ¬ ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ï¼ˆ1120å¤œã€€æ›´æ–°äºˆå®šï¼‰

### å˜èªåˆ†æ
**Debugä¸­**
<!-- ![å•è¯åˆ†ææ¼”ç¤º](assets/demos/word_analysis.gif) -->

### é•·æ–‡è§£æ - AIã«ã‚ˆã‚‹æ§‹æ–‡è§£æ
**æº–å‚™ä¸­**
<!-- ![å¥å­åˆ†ææ¼”ç¤º](assets/demos/sentence_analysis.gif) -->

[æ—¥æœ¬èª](#æ—¥æœ¬èª) | [English](#english-documentation)

---

## æ—¥æœ¬èª

### ğŸŒŸ æ¦‚è¦

EPUB ãƒªãƒ¼ãƒ€ãƒ¼ç”¨ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã§ã€æ—¥æœ¬èªå­¦ç¿’è€…å‘ã‘ã«ç‰¹åŒ–ã—ãŸé«˜åº¦ãªæ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚è¤‡æ•°ã® AI ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ã€åŒ…æ‹¬çš„ãªæ—¥æœ¬èªè¾æ›¸æ¤œç´¢ã¨å‹•è©æ´»ç”¨åˆ†æã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚

### âœ¨ ä¸»ãªæ©Ÿèƒ½

#### 1. ãƒãƒ«ãƒ AI ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ

ä»¥ä¸‹ã®ä¸»è¦ãª AI ã‚µãƒ¼ãƒ“ã‚¹ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆï¼š

- **OpenAI**
- **Anthropic Claude**
- **Google Gemini**
- **Ollama**
- âœ… **DeepSeek**
- âœ… **Echo**: ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ä»®æƒ³APIï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰

#### 2. é«˜åº¦ãªæ—¥æœ¬èªè¾æ›¸æ©Ÿèƒ½

**è¾æ›¸ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼š**
- Jim Breen æ°ã® JMdictï¼ˆæ—¥æœ¬èªå¤šè¨€èªè¾å…¸ï¼‰ã‚’æ¡ç”¨
- 18 ä¸‡èªä»¥ä¸Šã®åŒ…æ‹¬çš„ãªèªå½™ã‚«ãƒãƒ¬ãƒƒã‚¸
- èª­ã¿ä»®åã€å“è©ã€èªç¾©ã‚’å«ã‚€è©³ç´°ãªèªå½™æƒ…å ±

**å‹•è©æ´»ç”¨åˆ†æï¼š**

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯æ—¥æœ¬èªå‹•è©ã®æ´»ç”¨ã‚’è‡ªå‹•çš„ã«è­˜åˆ¥ã—ã€ç”Ÿæˆã—ã¾ã™ï¼š

- **å‹•è©åˆ†é¡ã®è‡ªå‹•åˆ¤å®š**ï¼šäº”æ®µæ´»ç”¨ï¼ˆä¸€é¡ï¼‰ã€ä¸€æ®µæ´»ç”¨ï¼ˆäºŒé¡ï¼‰ã€ã‚µè¡Œå¤‰æ ¼æ´»ç”¨ã€ã‚«è¡Œå¤‰æ ¼æ´»ç”¨
- **12 ç¨®é¡ã®æ´»ç”¨å½¢ã‚’å®Œå…¨ç”Ÿæˆ**ï¼š
  ```
  è¾æ›¸å½¢          â†’ èª­ã‚€
  ã¾ã™å½¢(ä¸å¯§ä½“)    â†’ èª­ã¿ã¾ã™
  ãªã„å½¢(å¦å®šå½¢)    â†’ èª­ã¾ãªã„
  å‘½ä»¤å½¢          â†’ èª­ã‚
  æ„å¿—å½¢(ã‚ˆã†å½¢)    â†’ èª­ã‚‚ã†
  å—èº«å½¢          â†’ èª­ã¾ã‚Œã‚‹
  ä½¿å½¹å½¢          â†’ èª­ã¾ã›ã‚‹
  å¯èƒ½å½¢          â†’ èª­ã‚ã‚‹
  ã°å½¢(ä»®å®šå½¢)     â†’ èª­ã‚ã°
  ã¦å½¢(æ¥ç¶šå½¢)     â†’ èª­ã‚“ã§
  ãŸå½¢(éå»å½¢)     â†’ èª­ã‚“ã 
  ãªã‹ã£ãŸå½¢       â†’ èª­ã¾ãªã‹ã£ãŸ
  ä½¿å½¹å—èº«å½¢       â†’ èª­ã¾ã›ã‚‰ã‚Œã‚‹
  ```

- **ä¿ƒéŸ³ä¾¿ãƒ»æ’¥éŸ³ä¾¿ãªã©ã®éŸ³ä¾¿è¦å‰‡ã«ã‚‚å¯¾å¿œ**

#### 3. ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ»ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ

**è‡ªå‹•åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ï¼š**
- çŸ­æ–‡ï¼ˆ1ã€œ10æ–‡å­—ï¼‰â†’ å˜èªåˆ†æãƒ¢ãƒ¼ãƒ‰
- é•·æ–‡ï¼ˆ10æ–‡å­—ä»¥ä¸Šï¼‰â†’ æ–‡ç« ãƒ»æ®µè½åˆ†æãƒ¢ãƒ¼ãƒ‰

**åˆ†æå†…å®¹ï¼š**
- ç¿»è¨³
- æ–‡æ³•ãƒã‚¤ãƒ³ãƒˆã®è§£èª¬
- JLPT ãƒ¬ãƒ™ãƒ«ä»˜ãèªå½™ãƒªã‚¹ãƒˆ
- å‹•è©æ´»ç”¨æƒ…å ±
- ç‰¹åˆ¥ãªãƒ’ãƒ³ãƒˆï¼šå¤ã„æ—¥æœ¬èªãªã©

### ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone < git@github.com:Syonling/epub_reader_backend.git >
cd epub_reader_backend

# Poetry ã‚’ä½¿ç”¨ã—ã¦ä¾èµ–é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
poetry install
```

#### è¨­å®š

`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼š

```python
FLASK_HOST=0.0.0.0
FLASK_PORT=5001
FLASK_DEBUG=True 

# å°‘ãªãã¨ã‚‚ 1 ã¤ã® API ã‚’è¨­å®šã—ã¦ãã ã•ã„
AI_PROVIDER=echo  #ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã™ã‚‹
# OpenAI
OPENAI_API_KEY=
OPENAI_MODEL=
# DeepSeek
DEEPSEEK_API_KEY=
DEEPSEEK_MODEL=
# Claude

# LLM é€šç”¨é…ç½®
MAX_TOKENS=1024
TEMPERATURE=0.7
TIMEOUT=30
```

#### èµ·å‹•

```bash
# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
poetry run python backend.py

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ http://localhost:5001 ã§å®Ÿè¡Œã•ã‚Œã¾ã™
```

### ğŸ”§ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

#### `/api/analyze` - ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼š**
```json
{
  "text": "èª­ã‚€",
  "provider": "openai",
  "model": "gpt-4",  
}
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¾‹ï¼ˆå˜èªåˆ†æï¼‰ï¼š**
```json
{
  "analysis": {
    "method": "word_parser",
    "result": {
      "translation": "read; peruse",
      "vocabulary": [{
        "word": "èª­ã‚€",
        "reading": "ã‚ˆã‚€",
        "meaning": "read; peruse",
        "level": "N2",
        "conjugation": {
          "has_conjugation": true,
          "verb_class": "äº”æ®µå‹•è©ï¼ˆä¸€é¡å‹•è©ï¼‰",
          "all_forms": {
            "masu_form": "èª­ã¿ã¾ã™",
            "te_form": "èª­ã‚“ã§",
            "ta_form": "èª­ã‚“ã ",
            // ... ãã®ä»–ã®æ´»ç”¨å½¢
          }
        }
      }],
      "special_notes": [
        "âœ… JMdict å®Œå…¨è¾æ›¸ã‚’ä½¿ç”¨ï¼ˆXML ç›´æ¥è§£æï¼‰"
      ]
    }
  }
}
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¾‹ï¼ˆæ–‡ç« åˆ†æï¼‰ï¼š**
```json
{
  "analysis": {
    "method": "ai_analysis",
    "provider": "openai",
    "model": "gpt-4",
    "result": {
      "translation": "æˆ‘æ¯å¤©éƒ½åœ¨å­¦ä¹ æ—¥è¯­ã€‚",
      "grammar_points": [
        {
          "pattern": "ã€œã¦ã„ã¾ã™",
          "explanation": "è¡¨ç¤ºåŠ¨ä½œçš„æŒç»­è¿›è¡Œæˆ–ä¹ æƒ¯æ€§åŠ¨ä½œ",
          "example_in_sentence": "å‹‰å¼·ã—ã¦ã„ã¾ã™",
          "level": "N5"
        }
      ],
      "vocabulary": [
        {
          "word": "æ¯æ—¥",
          "reading": "ã¾ã„ã«ã¡",
          "meaning": "æ¯å¤©",
          "level": "N5"
        },
        {
          "word": "å‹‰å¼·",
          "reading": "ã¹ã‚“ãã‚‡ã†",
          "meaning": "å­¦ä¹ ",
          "level": "N5"
        }
      ],
      "special_notes": [
        "è¿™æ˜¯ä¸€ä¸ªè¡¨è¾¾æ—¥å¸¸ä¹ æƒ¯çš„å¥å­"
      ]
    }
  }
}
```

#### `/api/health` - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¨åˆ©ç”¨å¯èƒ½ãª AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è¿”ã—ã¾ã™ã€‚

### ğŸ¯ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**ï¼šFlask 3.1.2
- **ä¾å­˜é–¢ä¿‚ç®¡ç†**ï¼šPoetry
- **æ—¥æœ¬èªè¾æ›¸**ï¼šJMdictï¼ˆXML ç›´æ¥è§£æï¼‰
- **AI çµ±åˆ**ï¼š
  - OpenAI Python SDK
  - Anthropic Python SDK
  - Google Generative AI SDK
  - Ollama Python SDK
  - ã‚«ã‚¹ã‚¿ãƒ  DeepSeek ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼

### ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
epub_reader_backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ middleware/          # ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚®ãƒ³ã‚°ç­‰ï¼‰
â”‚   â”œâ”€â”€ routes/              # API ãƒ«ãƒ¼ãƒˆ
â”‚   â”‚   â”œâ”€â”€ analysis.py      # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”‚   â”œâ”€â”€ health.py        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
â”‚   â”‚   â””â”€â”€ stats.py         # çµ±è¨ˆæƒ…å ±
â”‚   â”œâ”€â”€ services/            # ã‚³ã‚¢ã‚µãƒ¼ãƒ“ã‚¹
â”‚   â”‚   â”œâ”€â”€ ai_service.py           # AI ã‚µãƒ¼ãƒ“ã‚¹ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ japanese_word_parser.py # æ—¥æœ¬èªè¾æ›¸è§£æ
â”‚   â”‚   â”œâ”€â”€ verb_conjugator.py      # å‹•è©æ´»ç”¨ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ word_parser.py          # å˜èªè§£æå™¨
â”‚   â”‚   â””â”€â”€ text_analyzer.py        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æå™¨
â”‚   â””â”€â”€ utils/               # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
â”œâ”€â”€ backend.py               # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ config.py                # è¨­å®šç®¡ç†
â””â”€â”€ pyproject.toml           # ä¾å­˜é–¢ä¿‚å®šç¾©
```

### ğŸ’¡ æŠ€è¡“çš„ç‰¹å¾´

#### å­¦ç¿’è€…ä¸­å¿ƒã®è¨­è¨ˆ

æ—¥æœ¬èªå­¦ç¿’è€…ã€ç‰¹ã«ä¸­å›½èªæ¯èªè©±è€…ã®å®Ÿéš›ã®ãƒ‹ãƒ¼ã‚ºã‚’è€ƒæ…®ã—ãŸè¨­è¨ˆï¼š

- **å‹•è©æ´»ç”¨ã®é‡ç‚¹åŒ–**ï¼šæ—¥æœ¬èªæ–‡æ³•è¦å‰‡ã«åŸºã¥ã„ãŸç‹¬è‡ªã®æ´»ç”¨ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…ã€‚ä¿ƒéŸ³ä¾¿ã€æ’¥éŸ³ä¾¿ãªã©ã®éŸ³ä¾¿è¦å‰‡ã«ã‚‚å¯¾å¿œã—ã€æ­£ç¢ºãªæ´»ç”¨å½¢ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
- **æ–‡æ³•è§£æã®æœ€é©åŒ–**ï¼šå­¦ç¿’æ®µéšã«å¿œã˜ãŸ JLPT ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºã¨ã€è©³ç´°ãªæ–‡æ³•ãƒã‚¤ãƒ³ãƒˆè§£èª¬ã‚’æä¾›ã€‚
- **ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆåˆ¤å®š**ï¼šãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã«åŸºã¥ã„ã¦å˜èªåˆ†æã¨æ–‡ç« åˆ†æã‚’è‡ªå‹•é¸æŠã€‚

#### ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®é«˜ã„è¨­è¨ˆ

- **API å‘¼ã³å‡ºã—ã®æœ€é©åŒ–**ï¼šå˜èªåˆ†æã¯ãƒ­ãƒ¼ã‚«ãƒ«è¾æ›¸ã§å‡¦ç†ã—ã€AI API ã‚’ä½¿ç”¨ã—ãªã„ãŸã‚ã€ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«å‰Šæ¸›ã€‚
- **é¸æŠçš„ AI åˆ©ç”¨**ï¼šæ–‡ç« ã‚„æ®µè½ã®åˆ†ææ™‚ã®ã¿ AI API ã‚’å‘¼ã³å‡ºã—ã€ä¸è¦ãª API ä½¿ç”¨ã‚’å›é¿ã€‚
- **è¤‡æ•°ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œ**ï¼šãƒ‹ãƒ¼ã‚ºã«å¿œã˜ã¦æœ€é©ãª AI ã‚µãƒ¼ãƒ“ã‚¹ã‚’é¸æŠå¯èƒ½ã€‚

### ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

CC BY-NC 4.0ï¼ˆéå•†ç”¨åˆ©ç”¨ï¼‰

---

## English Documentation

### ğŸŒŸ Overview

A powerful backend service for an EPUB reader application, specifically designed for Japanese language learners. Supports multiple AI models, comprehensive Japanese dictionary lookups, and verb conjugation analysis.

### âœ¨ Key Features

#### 1. Multi-AI Model Support

Seamlessly integrated with major AI services:

- **OpenAI**: GPT-4, GPT-3.5, and other cutting-edge models
- **Anthropic Claude**: High-performance models including Claude 3.5 Sonnet
- **Google Gemini**: Gemini Pro, Gemini Flash
- **Ollama**: Privacy-focused local deployment
- **DeepSeek**: Cost-effective alternative

#### 2. Advanced Japanese Dictionary

**Dictionary Database:**
- Powered by Jim Breen's JMdict (Japanese-Multilingual Dictionary)
- 180,000+ comprehensive vocabulary coverage
- Custom implementation with direct XML parsing for fast and stable performance
- Detailed lexical information including readings, parts of speech, and definitions

**Verb Conjugation Analysis:**

The system automatically identifies and generates Japanese verb conjugations:

- **Automatic Verb Classification**: Godan (Type I), Ichidan (Type II), Suru-irregular, Kuru-irregular
- **12 Complete Conjugation Forms**:
  ```
  Dictionary Form        â†’ èª­ã‚€ (yomu)
  Masu Form (polite)     â†’ èª­ã¿ã¾ã™ (yomimasu)
  Te Form (connective)   â†’ èª­ã‚“ã§ (yonde)
  Ta Form (past)         â†’ èª­ã‚“ã  (yonda)
  Nai Form (negative)    â†’ èª­ã¾ãªã„ (yomanai)
  Nakatta Form           â†’ èª­ã¾ãªã‹ã£ãŸ (yomanakatta)
  Ba Form (conditional)  â†’ èª­ã‚ã° (yomeba)
  Command Form           â†’ èª­ã‚ (yome)
  Volitional Form        â†’ èª­ã‚‚ã† (yomou)
  Passive Form           â†’ èª­ã¾ã‚Œã‚‹ (yomareru)
  Causative Form         â†’ èª­ã¾ã›ã‚‹ (yomaseru)
  Potential Form         â†’ èª­ã‚ã‚‹ (yomeru)
  Causative-Passive      â†’ èª­ã¾ã›ã‚‰ã‚Œã‚‹ (yomaserareru)
  ```

- **Supports euphonic changes** (sound shifts in conjugation)

#### 3. Intelligent Text Analysis

**Automatic Detection:**
- Short text (1-3 characters) â†’ Word analysis mode
- Long text (4+ characters) â†’ Sentence/paragraph analysis mode

**Analysis Content:**
- Translation
- Grammar point explanations
- Vocabulary list with JLPT levels
- Verb conjugation information
- Learning tips

### ğŸš€ Setup

#### Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd epub_reader_backend

# Install dependencies using Poetry
poetry install

# Download dictionary data (about 23MB, takes a few minutes)
poetry run python setup_dict.py
```

#### Configuration

Create a `.env` file:

```env
# Configure at least one API
OPENAI_API_KEY=sk-xxx
ANTHROPIC_API_KEY=sk-ant-xxx
GEMINI_API_KEY=xxx
DEEPSEEK_API_KEY=sk-xxx

# For local Ollama usage
OLLAMA_BASE_URL=http://localhost:11434
```

#### Running

```bash
# Start the backend server
poetry run python backend.py

# Runs on http://localhost:5001 by default
```

### ğŸ”§ API Endpoints

#### `/api/analyze` - Text Analysis

**Request:**
```json
{
  "text": "èª­ã‚€",
  "provider": "openai",
  "model": "gpt-4",
  "force_type": "word"  // Optional: force word or sentence analysis
}
```

**Response Example (Word Analysis):**
```json
{
  "analysis": {
    "method": "word_parser",
    "result": {
      "translation": "read; peruse",
      "vocabulary": [{
        "word": "èª­ã‚€",
        "reading": "ã‚ˆã‚€",
        "meaning": "read; peruse",
        "level": "N2",
        "conjugation": {
          "has_conjugation": true,
          "verb_class": "Godan Verb (Type I)",
          "all_forms": {
            "masu_form": "èª­ã¿ã¾ã™",
            "te_form": "èª­ã‚“ã§",
            "ta_form": "èª­ã‚“ã ",
            // ... more conjugations
          }
        }
      }],
      "special_notes": [
        "âœ… Using complete JMdict dictionary (direct XML parsing)"
      ]
    }
  }
}
```

#### `/api/health` - Health Check

Returns backend status and available AI providers.

### ğŸ¯ Tech Stack

- **Backend Framework**: Flask 3.1.2
- **Dependency Management**: Poetry
- **Japanese Dictionary**: JMdict (direct XML parsing)
- **AI Integration**:
  - OpenAI Python SDK
  - Anthropic Python SDK
  - Google Generative AI SDK
  - Ollama Python SDK
  - Custom DeepSeek adapter

### ğŸ“ Project Structure

```
epub_reader_backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ middleware/          # Middleware (request logging, etc.)
â”‚   â”œâ”€â”€ routes/              # API routes
â”‚   â”‚   â”œâ”€â”€ analysis.py      # Text analysis endpoint
â”‚   â”‚   â”œâ”€â”€ health.py        # Health check
â”‚   â”‚   â””â”€â”€ stats.py         # Statistics
â”‚   â”œâ”€â”€ services/            # Core services
â”‚   â”‚   â”œâ”€â”€ ai_service.py           # AI service management
â”‚   â”‚   â”œâ”€â”€ japanese_word_parser.py # Japanese dictionary parser
â”‚   â”‚   â”œâ”€â”€ verb_conjugator.py      # Verb conjugation generator
â”‚   â”‚   â”œâ”€â”€ word_parser.py          # Word parser
â”‚   â”‚   â””â”€â”€ text_analyzer.py        # Text analyzer
â”‚   â””â”€â”€ utils/               # Utility functions
â”œâ”€â”€ backend.py               # Main entry point
â”œâ”€â”€ config.py                # Configuration management
â””â”€â”€ pyproject.toml           # Dependency definitions
```

### ğŸ’¡ Technical Highlights

#### Direct XML Parsing for JMdict

To avoid issues with traditional SQLite import (UNIQUE constraint errors), we implemented custom XML parsing. This provides:
- Improved stability
- Simplified setup
- Fast search performance

#### Verb Conjugation Implementation

Custom conjugation logic based on Japanese grammar rules, with support for euphonic changes, producing accurate conjugation forms.

### ğŸ“„ License

CC BY-NC 4.0 (Non-Commercial Use)

---
